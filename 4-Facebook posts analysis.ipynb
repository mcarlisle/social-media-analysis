{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we can discover about the overall sentiment of our Facebook posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import string\n",
    "\n",
    "# quick and dirty sentiment analysis; more complex to come\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "#from nltk.classify import NaiveBayesClassifier\n",
    "#from nltk.corpus import subjectivity\n",
    "#from nltk.sentiment import SentimentAnalyzer\n",
    "#from nltk.sentiment.util import *\n",
    "#from nltk.stem import PorterStemmer # or LancasterStemmer, RegexpStemmer, SnowballStemmer\n",
    "#from nltk.stem.wordnet import wordnet, WordNetLemmatizer\n",
    "#import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_sec_to_datetime(ts):\n",
    "    assert int(ts) > 0, \"must be nonnegative int\"\n",
    "    sts = str(ts)\n",
    "    return datetime.utcfromtimestamp(int(sts[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to download the vader_lexicon\n",
    "\n",
    "# nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_dir = \"./facebook-YOURNAMEHERE/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(facebook_dir + \"posts/your_posts_1.json\", \"r\") as f:\n",
    "    posts = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll attempt a simple sentiment analysis.\n",
    "\n",
    "Let's get all of one's Facebook posts from the list of JSON into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_meta = defaultdict(int)\n",
    "# rudimentary EDA: what keys are on each post?\n",
    "for i in range(len(posts)):\n",
    "    for k in posts[i].keys():\n",
    "        posts_meta[k] +=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many memories did you share? What is your memory-share-post-ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_posts = len(posts)\n",
    "memories_shared = 0\n",
    "# ASSUMPTION: This is always the form FB used.\n",
    "memory_sentence = \"shared a memory\" \n",
    "\n",
    "for i in range(total_posts):\n",
    "    if 'title' in posts[i].keys():\n",
    "        if memory_sentence in posts[i]['title']:\n",
    "            memories_shared += 1\n",
    "#            print(posts[i])\n",
    "            \n",
    "memory_post_ratio = 100 * round(memories_shared / total_posts, 4)\n",
    "            \n",
    "print(f\"Memories shared: {memories_shared} / {total_posts} = {memory_post_ratio}% of all posts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick & dirty sentiment analysis of all text posts\n",
    "# A text post resides in ['data'][j][k] for some j\n",
    "# for k in ('post', 'text', 'description')\n",
    "# or, use 'description' for a photo caption\n",
    "# ... for now, just pull 'post'. It's the most direct.\n",
    "\n",
    "text_keys = ('post', 'description')\n",
    "text_posts = []\n",
    "text_timestamps = []\n",
    "for i in range(len(posts)):\n",
    "    if 'data' in posts[i].keys():\n",
    "        for j in range(len(posts[i]['data'])):\n",
    "            for k in text_keys:\n",
    "                if k in posts[i]['data'][j]:\n",
    "                    text_posts.append(posts[i]['data'][j][k])\n",
    "                    text_timestamps.append(posts[i]['timestamp'])\n",
    "#    if 'attachments' in posts[i].keys():\n",
    "#        for j in range(len(posts[i]['attachments'])):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do a rudimentary sentiment analysis on these text posts with VADER (which has been trained on social media: https://github.com/cjhutto/vaderSentiment).\n",
    "\n",
    "We don't remove stopwords, lowercase, or otherwise clean the posts (besides removing \\n), as each idiosyncrasy may have sentimental value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll do a rudimentary sentiment analysis on these text posts with NLTK.\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_datetimes = [timestamp_sec_to_datetime(ts) for ts in text_timestamps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_posts_cleaned = []\n",
    "for t in text_posts:\n",
    "    text_posts_cleaned.append(t.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_dict_list = []\n",
    "for i in range(len(text_posts_cleaned)): \n",
    "    # still mostly uncleaned, and less Pythonic, yes\n",
    "#    print(sent)\n",
    "    ss = sid.polarity_scores(text_posts_cleaned[i])\n",
    "    ss['datetime'] = text_datetimes[i]\n",
    "    ss['post'] = text_posts_cleaned[i]\n",
    "#    for k in sorted(ss):\n",
    "#        print(f\"{k}: {ss[k]} \", end=\"\")\n",
    "    ss_dict_list.append(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect average sentiment per month in each category and plot them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DataFrame with date and each parameter in ss_dict.\n",
    "ss_dict_to_df = {}\n",
    "\n",
    "for k in ss_dict_list[0].keys():\n",
    "    ss_dict_to_df[k] = []\n",
    "\n",
    "for ss in ss_dict_list: \n",
    "    for k in ss.keys():\n",
    "        ss_dict_to_df[k].append(ss[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.DataFrame.from_dict(ss_dict_to_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each month, take the average of each score.\n",
    "# Group by year, then month. TODO Multi-index instead.\n",
    "sentiment_df['year']  = list(map(lambda x: x.year,  sentiment_df['datetime']))\n",
    "sentiment_df['month'] = list(map(lambda x: x.month, sentiment_df['datetime']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_years = sorted(list(sentiment_df['year'].unique()))\n",
    "sentiment_scores = ['neg', 'neu', 'pos', 'compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_post_sentiment_evolution = {}\n",
    "times = []\n",
    "for score in sentiment_scores:\n",
    "    fb_post_sentiment_evolution[score] = []\n",
    "    for y in fb_years:\n",
    "        for m in range(1,13):\n",
    "            val = sentiment_df[(sentiment_df['year']==y)\n",
    "                             & (sentiment_df['month']==m)][score].mean()\n",
    "            if not np.isnan(val): # only list actual numbers\n",
    "                fb_post_sentiment_evolution[score].append(val)\n",
    "                if score == 'pos': \n",
    "                    time = round(y + m/12, 3)    \n",
    "                    # give an approx decimal value for the end of that month. \n",
    "                    times.append(time) # only do this once; hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all of these averages.\n",
    "\n",
    "plt.plot(times, fb_post_sentiment_evolution['pos'])\n",
    "plt.plot(times, fb_post_sentiment_evolution['neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's get box plots per year. Separate the sentiment scores into columns by year.\n",
    "fb_post_sentiment_boxplots = {}\n",
    "for score in sentiment_scores:\n",
    "    fb_post_sentiment_boxplots[score] = []\n",
    "    for y in fb_years:\n",
    "        fb_post_sentiment_boxplots[score].append(list(sentiment_df[sentiment_df['year']==y][score]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fb_years\n",
    "#fb_post_sentiment_boxplots\n",
    "plt.boxplot(fb_post_sentiment_boxplots['pos'], labels=fb_years)\n",
    "plt.title(\"Facebook post positive sentiment by year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(fb_post_sentiment_boxplots['neg'], labels=fb_years)\n",
    "plt.title(\"Facebook post negative sentiment by year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(fb_post_sentiment_boxplots['neu'], labels=fb_years)\n",
    "plt.title(\"Facebook post neutral sentiment by year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(fb_post_sentiment_boxplots['compound'], labels=fb_years)\n",
    "plt.title(\"Facebook post compound sentiment by year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas for future analysis: \n",
    "    \n",
    "    * Year breakdown of memories shared\n",
    "    * Sentiment analysis on the text of the post, and any text on an attachment to the post.\n",
    "    * Sentiment analysis on any image attached to the post.\n",
    "    * Sentiment analysis on key frames of a video attached to the post.\n",
    "    * Build overall counts for the types of titles on the posts:\n",
    "        * regular post\n",
    "        * post share\n",
    "        * image share\n",
    "        * video share\n",
    "        * memory share\n",
    "        * Twitter share\n",
    "        * Instagram share\n",
    "        * other share?\n",
    "        * other kinds of posts?\n",
    "    * Unsupervised topic modeling\n",
    "    * Correlate / otherwise associate likes/reactions to posts to sentiment/topic?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
